{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Import relevant packages\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import glob\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"/Users/karangarg/Documents/Year 3 Modules/EC331/Code/rae_repo/lstms/lstm1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_data(filepath): #Returns a dictionary where each item is a df containing one run. One dict per generation.\n",
    "    all_files = glob.glob(filepath + \"/*.csv\")\n",
    "    name_list = []\n",
    "    datadict = {}\n",
    "    for f in all_files:\n",
    "        name_list.append(f[77:-4])\n",
    "    for i,n in enumerate(name_list):\n",
    "        datadict[n] = pd.read_csv(all_files[i], header=0)\n",
    "    for k, v in datadict.items():\n",
    "        v.drop(columns=[\"Unnamed: 0\", \"volume\", \"spread\", \"10_MA\", \"50_MA\"], inplace=True)\n",
    "    return datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen0 = unpack_data(\"/Users/karangarg/Documents/Year 3 Modules/EC331/Code/rae_repo//simulations/gen0_sims/data\") #Load gen0 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(datadict, window): #Turn dictionaries of data into features and samples lists\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for k, v in datadict.items():\n",
    "        for i in range(len(v)):\n",
    "            if i >= window:\n",
    "                y_data.append(v.iloc[i][\"trading_price\"])\n",
    "                xi = v.iloc[i-window:i].to_numpy()\n",
    "                x_data.append(xi)\n",
    "    x_data = np.array(x_data)\n",
    "    y_data = np.array(y_data)\n",
    "    y_data = np.reshape(y_data, (y_data.shape[0], 1))\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31380, 20, 2)\n",
      "(31380, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = format_data(gen0, 20)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(xarray, yarray): #Take the natural log and then normalise prices\n",
    "    yarray_log = np.log(yarray)\n",
    "    xarray_log = np.log(xarray)\n",
    "    xsc = StandardScaler()\n",
    "    instances, timesteps, features = xarray_log.shape\n",
    "    xarray_log = np.reshape(xarray_log, (-1, features))\n",
    "    xarray_norm = xsc.fit_transform(xarray_log)\n",
    "    xarray_norm = np.reshape(xarray_norm, (instances, timesteps, features))\n",
    "    ysc = StandardScaler().fit(yarray_log)\n",
    "    yarray_norm = ysc.transform(yarray_log)\n",
    "    return xarray_norm, yarray_norm, xsc, ysc\n",
    "\n",
    "def split_data(xarray, yarray, trainratio): #Split the data into training and test sets\n",
    "    train_len = int(len(xarray)*trainratio)\n",
    "    test_len = len(xarray) - train_len\n",
    "    x_train, y_train, x_test, y_test = xarray[:train_len], yarray[:train_len], xarray[train_len:], yarray[train_len:]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_data(X, y, 0.8)\n",
    "X_train, y_train, Xscale, yscale = normalise_data(X_train, y_train)\n",
    "X_test, y_test, _, _ = normalise_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"/Users/karangarg/Documents/Year 3 Modules/EC331/Code/rae_repo/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20083 samples, validate on 5021 samples\n",
      "Epoch 1/10\n",
      "20083/20083 [==============================] - 30s 1ms/sample - loss: 0.2348 - val_loss: 0.0077\n",
      "Epoch 2/10\n",
      "20083/20083 [==============================] - 22s 1ms/sample - loss: 0.0377 - val_loss: 0.0066\n",
      "Epoch 3/10\n",
      "20083/20083 [==============================] - 22s 1ms/sample - loss: 0.0280 - val_loss: 0.0176\n",
      "Epoch 4/10\n",
      "20083/20083 [==============================] - 23s 1ms/sample - loss: 0.0228 - val_loss: 0.0048\n",
      "Epoch 5/10\n",
      "20083/20083 [==============================] - 22s 1ms/sample - loss: 0.0218 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "20083/20083 [==============================] - 22s 1ms/sample - loss: 0.0201 - val_loss: 0.0031\n",
      "Epoch 7/10\n",
      "20083/20083 [==============================] - 25s 1ms/sample - loss: 0.0196 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "20083/20083 [==============================] - 25s 1ms/sample - loss: 0.0186 - val_loss: 0.0067\n",
      "Epoch 9/10\n",
      "20083/20083 [==============================] - 21s 1ms/sample - loss: 0.0183 - val_loss: 0.0156\n",
      "Epoch 10/10\n",
      "20083/20083 [==============================] - 23s 1ms/sample - loss: 0.0192 - val_loss: 0.0014\n"
     ]
    }
   ],
   "source": [
    "lstm1=keras.Sequential() #Set up the architecture of the model\n",
    "\n",
    "lstm1.add(layers.LSTM(units=16, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "lstm1.add(layers.Dropout(0.2))\n",
    "\n",
    "lstm1.add(layers.Dense(units=1))\n",
    "\n",
    "lstm1.compile(optimizer='nadam', loss='mean_squared_error') #Compile and train the model\n",
    "\n",
    "history1 = lstm1.fit(X_train, y_train, epochs = 10, batch_size = 32, validation_split=0.2, shuffle=False, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TENSORBOARD_BINARY'] = '/Users/karangarg/Documents/Year 3 Modules/EC331/Code/rae_repo/to/envs/my_env/bin/tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find '/Users/karangarg/Documents/Year 3\n",
       "Modules/EC331/Code/rae_repo/to/envs/my_env/bin/tensorboard' (set by\n",
       "the `TENSORBOARD_BINARY` environment variable). Please ensure that\n",
       "your PATH contains an executable `tensorboard` program, or explicitly\n",
       "specify the path to a TensorBoard binary by setting the\n",
       "`TENSORBOARD_BINARY` environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --log_dir logs/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find '/Users/karangarg/Documents/Year 3\n",
       "Modules/EC331/Code/rae_repo/to/envs/my_env/bin/tensorboard' (set by\n",
       "the `TENSORBOARD_BINARY` environment variable). Please ensure that\n",
       "your PATH contains an executable `tensorboard` program, or explicitly\n",
       "specify the path to a TensorBoard binary by setting the\n",
       "`TENSORBOARD_BINARY` environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir=\"/Users/karangarg/Documents/Year 3 Modules/EC331/Code/rae_repo/logs/fit/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
